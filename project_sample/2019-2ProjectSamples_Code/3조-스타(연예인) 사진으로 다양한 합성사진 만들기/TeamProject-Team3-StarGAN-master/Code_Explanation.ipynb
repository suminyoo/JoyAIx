{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 페이지는 본 프로젝트의 코드를 설명하는 부분입니다. <br/>\n",
    "실제 구현은 README.md에 있는 Google Drive에서 파일을 다운받아서 실행해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로그램을 실행하는데 있어서 필요한 모듈들을 import 하는 부분입니다.\n",
    "##### os 모듈은 자료를 학습시키는데에 필요한 자료를 불러오는데 쓰이는 모듈이고,argparse 모듈은 코드를 돌리는데 필요한 입력값들을 효과적으로 저장하는데에 필요한 모듈입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os # os 모듈을 가져옴\n",
    "import argparse # argparse 모듈을 가져옴 \n",
    "from solver import Solver  #solver모듈에서 Solver 를 가져옴\n",
    "from data_loader import get_loader  # data_loader에서 get_loader를 가져옴\n",
    "from torch.backends import cudnn  #torch.backends모듈에서 cudnn를 가져옴\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## str을 bool type 으로 바꿔주는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):# str을 bool type 으로 바꿔주는 함수 \n",
    "    return v.lower() in ('true') \n",
    "#입력받은 문자열 값을 소문자로 바꾼 값이 'true'의 부분집합이면 True를 아니면 False 값을 반환 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 지정된 모듈들과 입력된 데이터로 적절한 가중치와 편향을 구하는  main 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # For fast training.\n",
    "    cudnn.benchmark = True \n",
    "    # benchmark=True는 input tensor의 크기와 현재 사용중인 hardware에 따라 cudnn에서 사용하는 알고리즘을 바꿔줌.\n",
    "\n",
    "    # Create directories if not exist. 만약 디렉토리가 없으면 필요한 디렉토리 만드는 코드\n",
    "    if not os.path.exists(config.log_dir):\n",
    "        os.makedirs(config.log_dir)\n",
    "    if not os.path.exists(config.model_save_dir):\n",
    "        os.makedirs(config.model_save_dir)\n",
    "    if not os.path.exists(config.sample_dir):\n",
    "        os.makedirs(config.sample_dir)\n",
    "    if not os.path.exists(config.result_dir):\n",
    "        os.makedirs(config.result_dir)\n",
    "\n",
    "    # Data loader.\n",
    "    celeba_loader = None  #celeba_loader변수에 None값을 저장\n",
    "    rafd_loader = None  #rafd_loader변수에 None값을 저장\n",
    "\n",
    "    # 'CelebA', 'RaFD' 중 하나의 이미지 세트를 선택했으면 선택한 이미지 세트를 get_loader함수로 컴퓨터가 인식할 수 있게하여 \n",
    "    # 위에서 만든 변수에 저장하고  만약 'Both'를 선택했다면 둘 모두를 변수에 저장\n",
    "    \n",
    "    if config.dataset in ['CelebA', 'Both']:\n",
    "        celeba_loader = get_loader(config.celeba_image_dir, config.attr_path, config.selected_attrs,\n",
    "                                   'CelebA', config.mode, config.num_workers)\n",
    "    if config.dataset in ['RaFD', 'Both']:\n",
    "        rafd_loader = get_loader(config.rafd_image_dir, None, None,\n",
    "                                 config.rafd_crop_size, config.image_size, config.batch_size,\n",
    "                                 'RaFD', config.mode, config.num_workers)\n",
    "    \n",
    "\n",
    "    # Solver for training and testing StarGAN.\n",
    "    solver = Solver(celeba_loader, rafd_loader, config)\n",
    "\n",
    "    if config.mode == 'train':                             # 만약 학습모드이면 \n",
    "        if config.dataset in ['CelebA', 'RaFD']:       #config.dataset에 'CelebA', 'RaFD' 중 하나가 저장되있으면\n",
    "            solver.train()                                   #solver 객체에 train()함수를 실행\n",
    "        elif config.dataset in ['Both']:               #config.dataset에 'Both'가 저장되있으면\n",
    "            solver.train_multi()                           #solver 객체에 train_multi()함수를 실행\n",
    "    \n",
    "    \n",
    "    elif config.mode == 'test':                           #만약 테스트 모드이면\n",
    "        if config.dataset in ['CelebA', 'RaFD']:       #config.dataset에 'CelebA', 'RaFD' 중 하나가 저장되있으면\n",
    "            solver.test()                                    #solver 객체에 test()함수를 실행\n",
    "        elif config.dataset in ['Both']:               #config.dataset에 'Both'가 저장되있으면   \n",
    "            solver.test_multi()                            #solver 객체에 test_multi()함수를 실행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드의 첫시작 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':# 이 부분에서 부터 시작함을 명시하는 코드\n",
    "    \n",
    "    parser = argparse.ArgumentParser()#argparse.ArgumentParser를 통해 parse라는 이름의 객체를 생성한다.\n",
    "\n",
    "    # parser.add_argument를 이용하여 조건에 맞게 인자들을 입력받는다.\n",
    "    \n",
    "    # Model configuration. 모델에 필요한 값들을 설정 \n",
    "    parser.add_argument('--c_dim', type=int, default=5, help='dimension of domain labels (1st dataset)') #1st dataset 의 차원을 설정 기본값은 5\n",
    "    parser.add_argument('--c2_dim', type=int, default=8, help='dimension of domain labels (2nd dataset)')  #2nd dataset 의 차원을 설정 기본값은 5\n",
    "    parser.add_argument('--celeba_crop_size', type=int, default=178, help='crop size for the CelebA dataset') #crop size for the CelebA dataset의 사이즈 조절 기본값은 128x128\n",
    "    parser.add_argument('--rafd_crop_size', type=int, default=256, help='crop size for the RaFD dataset')       #crop size for the RaFD dataset의 사이즈 조절 기본값은 128x128\n",
    "    parser.add_argument('--image_size', type=int, default=128, help='image resolution') # 이미지 사이즈 조절 기본값은 128x128픽셀\n",
    "    parser.add_argument('--g_conv_dim', type=int, default=64, help='number of conv filters in the first layer of G')#\n",
    "    parser.add_argument('--d_conv_dim', type=int, default=64, help='number of conv filters in the first layer of D')#\n",
    "    parser.add_argument('--g_repeat_num', type=int, default=6, help='number of residual blocks in G')#\n",
    "    parser.add_argument('--d_repeat_num', type=int, default=6, help='number of strided conv layers in D')#\n",
    "    parser.add_argument('--lambda_cls', type=float, default=1, help='weight for domain classification loss')#\n",
    "    parser.add_argument('--lambda_rec', type=float, default=10, help='weight for reconstruction loss')#\n",
    "    parser.add_argument('--lambda_gp', type=float, default=10, help='weight for gradient penalty')# \n",
    "    \n",
    "    # Training configuration. 훈련에 필요한 값들을 설정 \n",
    "    parser.add_argument('--dataset', type=str, default='CelebA', choices=['CelebA', 'RaFD', 'Both']) #'중 하나를 선택해서 저장'CelebA', 'RaFD', 'Both' 기본값은 'CelebA'\n",
    "    parser.add_argument('--batch_size', type=int, default=8, help='mini-batch size')# 배치사이즈 조절 기본값은 8 사이즈\n",
    "    parser.add_argument('--num_iters', type=int, default=200000, help='number of total iterations for training D')\n",
    "    parser.add_argument('--num_iters_decay', type=int, default=100000, help='number of iterations for decaying lr')\n",
    "    parser.add_argument('--g_lr', type=float, default=0.0001, help='learning rate for G')#학습률\n",
    "    parser.add_argument('--d_lr', type=float, default=0.0001, help='learning rate for D')#\n",
    "    parser.add_argument('--n_critic', type=int, default=5, help='number of D updates per each G update')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "    parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "    parser.add_argument('--resume_iters', type=int, default=None, help='resume training from this step')\n",
    "    parser.add_argument('--selected_attrs', '--list', nargs='+', help='selected attributes for the CelebA dataset',\n",
    "                        default=['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'])\n",
    "\n",
    "    # Test configuration. 테스트에 필요한 값들을 설정 \n",
    "    parser.add_argument('--test_iters', type=int, default=200000, help='test model from this step') \n",
    "\n",
    "    # Miscellaneous.\n",
    "    parser.add_argument('--num_workers', type=int, default=1)\n",
    "    parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])# 학습모드인지 테스트 모드인지 선택\n",
    "    parser.add_argument('--use_tensorboard', type=str2bool, default=True)          \n",
    "\n",
    "    # Directories. 학습에 필요한 자료를 가져올 파일 이름을 설정\n",
    "    parser.add_argument('--celeba_image_dir', type=str, default='data/celeba/images')\n",
    "    parser.add_argument('--attr_path', type=str, default='data/celeba/list_attr_celeba.txt')\n",
    "    parser.add_argument('--rafd_image_dir', type=str, default='data/RaFD/train')\n",
    "    parser.add_argument('--log_dir', type=str, default='stargan/logs')\n",
    "    parser.add_argument('--model_save_dir', type=str, default='stargan/models')\n",
    "    parser.add_argument('--sample_dir', type=str, default='stargan/samples')\n",
    "    parser.add_argument('--result_dir', type=str, default='stargan/results')\n",
    "\n",
    "    # Step size. 스텝 사이즈\n",
    "    parser.add_argument('--log_step', type=int, default=10)\n",
    "    parser.add_argument('--sample_step', type=int, default=1000)\n",
    "    parser.add_argument('--model_save_step', type=int, default=10000)\n",
    "    parser.add_argument('--lr_update_step', type=int, default=1000)\n",
    "\n",
    "    config = parser.parse_args()#  parser.parse_args 함수를 통해 인자들을 파싱하여 args에 저장하고 이값을 config 에 할당. \n",
    "                                #각 인자는 add_argument의 type에 지정된 형식으로 저장된다.\n",
    "\n",
    "    print(config)                    #config 값을 프린트\n",
    "    main(config)                    #config을 main 함수에 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solver.py\n",
    "--------------------------------------\n",
    "solver.py는 main.py에서 사용할 다양한 함수들에 대한 선언과 구현을 하는 코드입니다.<br/>\n",
    "우선 solver class에 정의된 함수들을 각각 살펴보겠습니다. (학습에 크게 영향이 없거나 설명이 불필요한 함수는 생략하였습니다)\n",
    "\n",
    "* _init_(): 함수는 전반적인 학습을 위한 파라미터들에 대한 세팅을 해주는 함수입니다. 이는 main.py에서 사용자로부터 직접 입력받은 값을 넘겨받아서 정의해주게 됩니다. 구체적으로는 학습데이터 로딩, 영상의 여러 도메인에 대한 레이블링, 학습횟수, 학습모델, 저장 경로 등에 대한 설정입니다. 코드의 주석을 참고해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, celeba_loader, rafd_loader, config):\n",
    "        \"\"\"Initialize configurations.\"\"\"\n",
    "\n",
    "        # Data loader.\n",
    "        self.celeba_loader = celeba_loader\n",
    "        self.rafd_loader = rafd_loader\n",
    "\n",
    "        # Model configurations. (도메인 레이블들의 차원, convolution filter의 수, residual blocks의 수 등)\n",
    "        self.c_dim = config.c_dim\n",
    "        self.c2_dim = config.c2_dim\n",
    "        self.image_size = config.image_size\n",
    "        self.g_conv_dim = config.g_conv_dim\n",
    "        self.d_conv_dim = config.d_conv_dim\n",
    "        self.g_repeat_num = config.g_repeat_num\n",
    "        self.d_repeat_num = config.d_repeat_num\n",
    "        self.lambda_cls = config.lambda_cls\n",
    "        self.lambda_rec = config.lambda_rec\n",
    "        self.lambda_gp = config.lambda_gp\n",
    "\n",
    "        # Training configurations. (데이터집합, mini-batch 크기, 학습 iteration 횟수, learning rate 등)\n",
    "        self.dataset = config.dataset\n",
    "        self.batch_size = config.batch_size\n",
    "        self.num_iters = config.num_iters\n",
    "        self.num_iters_decay = config.num_iters_decay\n",
    "        self.g_lr = config.g_lr\n",
    "        self.d_lr = config.d_lr\n",
    "        self.n_critic = config.n_critic\n",
    "        self.beta1 = config.beta1\n",
    "        self.beta2 = config.beta2\n",
    "        self.resume_iters = config.resume_iters\n",
    "        self.selected_attrs = config.selected_attrs\n",
    "\n",
    "        # Test configurations. (학습된 모델 정하기)\n",
    "        self.test_iters = config.test_iters\n",
    "\n",
    "        # Miscellaneous. (학습에 사용되는 설정)\n",
    "        self.use_tensorboard = config.use_tensorboard\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Directories. (다양한 파일의 저장 경로)\n",
    "        self.log_dir = config.log_dir\n",
    "        self.sample_dir = config.sample_dir\n",
    "        self.model_save_dir = config.model_save_dir\n",
    "        self.result_dir = config.result_dir\n",
    "\n",
    "        # Step size. (각 항목의 update/save 빈도수)\n",
    "        self.log_step = config.log_step\n",
    "        self.sample_step = config.sample_step\n",
    "        self.model_save_step = config.model_save_step\n",
    "        self.lr_update_step = config.lr_update_step\n",
    "\n",
    "        # Build the model and tensorboard.\n",
    "        self.build_model()\n",
    "        if self.use_tensorboard:\n",
    "            self.build_tensorboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* build_model(): GAN모델에 사용되는 generator와 discriminator를 빌드해주는 함수입니다. 현재 데이터집합 별로 학습에 사용하는 도메인 차원의 수, 레이블 차원의 수 등이 다르므로 다르게 지정해줍니다. 또한 손실함수로는 Adam 함수를 사용하게됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(self):\n",
    "        \"\"\"Create a generator and a discriminator.\"\"\"\n",
    "        '''generator와 discrimiator를 생성'''\n",
    "        if self.dataset in ['CelebA', 'RaFD']:\n",
    "            self.G = Generator(self.g_conv_dim, self.c_dim, self.g_repeat_num)\n",
    "            self.D = Discriminator(self.image_size, self.d_conv_dim, self.c_dim, self.d_repeat_num) \n",
    "        elif self.dataset in ['Both']:\n",
    "            self.G = Generator(self.g_conv_dim, self.c_dim+self.c2_dim+2, self.g_repeat_num)   # 2 for mask vector.\n",
    "            self.D = Discriminator(self.image_size, self.d_conv_dim, self.c_dim+self.c2_dim, self.d_repeat_num)\n",
    "\n",
    "        # 손실함수로는 Adam 함수를 사용\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), self.g_lr, [self.beta1, self.beta2])\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), self.d_lr, [self.beta1, self.beta2])\n",
    "        self.print_network(self.G, 'G')\n",
    "        self.print_network(self.D, 'D')\n",
    "            \n",
    "        self.G.to(self.device)\n",
    "        self.D.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print_network(): 네트워크의 정보를 출력해줍니다. (네트워크에 사용된 파라미터의 갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def print_network(self, model, name):\n",
    "        \"\"\"Print out the network information.\"\"\"\n",
    "        '''네트워크 정보를 출력'''\n",
    "        num_params = 0\n",
    "        for p in model.parameters():\n",
    "            num_params += p.numel()\n",
    "        print(model)\n",
    "        print(name)\n",
    "        print(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* restore_model(): 미리 학습된 모델(generator & discriminator)를 불러온다. (가장 최근 저장된 모델을 불러온다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(self, resume_iters):\n",
    "        \"\"\"Restore the trained generator and discriminator.\"\"\"\n",
    "        '''학습된 모델들을 가져온다'''\n",
    "        print('Loading the trained models from step {}...'.format(resume_iters))\n",
    "        G_path = os.path.join(self.model_save_dir, '{}-G.ckpt'.format(resume_iters))\n",
    "        D_path = os.path.join(self.model_save_dir, '{}-D.ckpt'.format(resume_iters))\n",
    "        self.G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
    "        self.D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* build_tensorboard(): 실시간 학습 상황을 관찰하고 비교할 수 있도록 tensorboard를 구축한다. (tensorboard 구축에 관한 자세한 코드는 logger.py 파일에 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tensorboard(self):\n",
    "        \"\"\"Build a tensorboard logger.\"\"\"\n",
    "        '''tensorboard를 구축한다 (실시간 학습 상황을 보기 위함)'''\n",
    "        from logger import Logger\n",
    "        self.logger = Logger(self.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* update_lr(): 초기 지정한 learning rate를 업데이트 한다. learning rate를 조절(순차적 감소)을 하는 이유는 초기에 경사하강법을 적용할때 값을 조정하는 보폭을 크게하여 빠르게 전역 최소점을 찾아가고, 점점 보폭을 작게하여 그 최소점이 계속 맴돌지 않고 올바른 최소점으로 찾아갈 수 있도록 조정해주기 위함입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(self, g_lr, d_lr):\n",
    "        \"\"\"Decay learning rates of the generator and discriminator.\"\"\"\n",
    "        '''각 learning rate를 업데이트한다'''\n",
    "        for param_group in self.g_optimizer.param_groups:\n",
    "            param_group['lr'] = g_lr\n",
    "        for param_group in self.d_optimizer.param_groups:\n",
    "            param_group['lr'] = d_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* label2onehot(): 레이블을 one-hot vector 형식으로 변형시켜준다. one-hot vector는 중복된 데이터를 제거하고 순서대로 데이터를 저장할 수 있다는 장점이 있기때문에 이러한 작업을 통해 데이터집합을 정리하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(self, labels, dim):\n",
    "        \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "        '''레이블을 one-hot vector 형식으로 만들어준다'''\n",
    "        batch_size = labels.size(0)\n",
    "        out = torch.zeros(batch_size, dim)\n",
    "        out[np.arange(batch_size), labels.long()] = 1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create_labels(): 디버깅과 테스트를 위한 target domain label을 생성하는 함수입니다. 코드에 있는 hair color 관련 내용들은 논문 작성자들에 의하면 따로 hair color이라는 [black,blond,brown,gray] attribute를 추가하기 위하여 직접 하드코딩하였다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(self, c_org, c_dim=5, dataset='CelebA', selected_attrs=None):\n",
    "        \"\"\"Generate target domain labels for debugging and testing.\"\"\"\n",
    "        '''debug와 test를 위한 target domain label을 생성'''\n",
    "        # Get hair color indices.\n",
    "        if dataset == 'CelebA':\n",
    "            hair_color_indices = []\n",
    "            for i, attr_name in enumerate(selected_attrs):\n",
    "                if attr_name in ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']:\n",
    "                    hair_color_indices.append(i)\n",
    "\n",
    "        c_trg_list = []\n",
    "        for i in range(c_dim):\n",
    "            if dataset == 'CelebA':\n",
    "                c_trg = c_org.clone()\n",
    "                if i in hair_color_indices:  # Set one hair color to 1 and the rest to 0.\n",
    "                    c_trg[:, i] = 1\n",
    "                    for j in hair_color_indices:\n",
    "                        if j != i:\n",
    "                            c_trg[:, j] = 0\n",
    "                else:\n",
    "                    c_trg[:, i] = (c_trg[:, i] == 0)  # Reverse attribute value.\n",
    "            elif dataset == 'RaFD':\n",
    "                c_trg = self.label2onehot(torch.ones(c_org.size(0))*i, c_dim)\n",
    "\n",
    "            c_trg_list.append(c_trg.to(self.device))\n",
    "        return c_trg_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* classification_loss(): 이는 확률분포 계산에 많이 사용되는 binary/softmax cross entropy loss를 사용하였다고 합니다. 코드상 구현은 특별히 어렵지 않은 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_loss(self, logit, target, dataset='CelebA'):\n",
    "        \"\"\"Compute binary or softmax cross entropy loss.\"\"\"\n",
    "        '''확률분포 계산에 많이 사용되는 binary/softmax cross entropy loss 사용'''\n",
    "        if dataset == 'CelebA':\n",
    "            return F.binary_cross_entropy_with_logits(logit, target, size_average=False) / logit.size(0)\n",
    "        elif dataset == 'RaFD':\n",
    "            return F.cross_entropy(logit, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train(): 실질적으로 본 StarGAN 모델의 학습이 이루어지는 함수입니다. 이 함수는 한가지의 데이터집합으로 학습할때 사용되고, 여러가지 데이터집합을 합쳐서 사용하게 될때는 실제 코드에 있는 train_multi() 함수를 사용하면 됩니다. 해당 함수는 굉장히 라인수가 길기 때문에 주석으로 해석을 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "        \"\"\"Train StarGAN within a single dataset.\"\"\"\n",
    "        # Set data loader. 학습에 사용될 데이터집합을 선택하여 알맞은 데이터집합을 로드한다.\n",
    "        if self.dataset == 'CelebA':\n",
    "            data_loader = self.celeba_loader\n",
    "        elif self.dataset == 'RaFD':\n",
    "            data_loader = self.rafd_loader\n",
    "\n",
    "        # Fetch fixed inputs for debugging. 디버깅을 위해서 고정된 input을 사용한다.\n",
    "        data_iter = iter(data_loader)\n",
    "        x_fixed, c_org = next(data_iter)\n",
    "        x_fixed = x_fixed.to(self.device)\n",
    "        c_fixed_list = self.create_labels(c_org, self.c_dim, self.dataset, self.selected_attrs)\n",
    "\n",
    "        # Learning rate cache for decaying. 업데이트된 learning rate값을 실제 학습에 사용되는 learning rate 변수에 저장해준다.\n",
    "        g_lr = self.g_lr\n",
    "        d_lr = self.d_lr\n",
    "\n",
    "        # Start training from scratch or resume training. 학습이 처음부터 이루어지는지, 중간에 중단한 학습을 이어서 학습할지에 따라 학습횟수를 조정하고 학습된 모델을 로딩해옵니다.\n",
    "        start_iters = 0\n",
    "        if self.resume_iters:\n",
    "            start_iters = self.resume_iters\n",
    "            self.restore_model(self.resume_iters)\n",
    "\n",
    "        # Start training.\n",
    "        print('Start training...')\n",
    "        start_time = time.time()\n",
    "        for i in range(start_iters, self.num_iters):\n",
    "\n",
    "            # =================================================================================== #\n",
    "            #                             1. Preprocess input data                                #\n",
    "            # =================================================================================== #\n",
    "\n",
    "            # Fetch real images and labels. 실제 영상과 그에 대한 레이블을 가져온다.\n",
    "            try:\n",
    "                x_real, label_org = next(data_iter)\n",
    "            except:\n",
    "                data_iter = iter(data_loader)\n",
    "                x_real, label_org = next(data_iter)\n",
    "\n",
    "            # Generate target domain labels randomly.\n",
    "            rand_idx = torch.randperm(label_org.size(0))\n",
    "            label_trg = label_org[rand_idx]\n",
    "\n",
    "            if self.dataset == 'CelebA':\n",
    "                c_org = label_org.clone()\n",
    "                c_trg = label_trg.clone()\n",
    "            elif self.dataset == 'RaFD':\n",
    "                c_org = self.label2onehot(label_org, self.c_dim)\n",
    "                c_trg = self.label2onehot(label_trg, self.c_dim)\n",
    "\n",
    "            x_real = x_real.to(self.device)           # Input images.\n",
    "            c_org = c_org.to(self.device)             # Original domain labels.\n",
    "            c_trg = c_trg.to(self.device)             # Target domain labels.\n",
    "            label_org = label_org.to(self.device)     # Labels for computing classification loss.\n",
    "            label_trg = label_trg.to(self.device)     # Labels for computing classification loss.\n",
    "\n",
    "            # =================================================================================== #\n",
    "            #                             2. Train the discriminator                              #\n",
    "            # =================================================================================== #\n",
    "            # discriminator의 기본적인 역할은 generator가 생성한 fake영상을 진짜 영상인지 합성된 fake영상인지 구분하는 모델입니다.\n",
    "            # 따라서 실제 영상과 fake 영상에 대한 손실량을 각각 구하고 이를 통하여 판별하게됩니다.\n",
    "            \n",
    "            # Compute loss with real images. \n",
    "            out_src, out_cls = self.D(x_real)\n",
    "            d_loss_real = - torch.mean(out_src)\n",
    "            d_loss_cls = self.classification_loss(out_cls, label_org, self.dataset)\n",
    "\n",
    "            # Compute loss with fake images.\n",
    "            x_fake = self.G(x_real, c_trg)\n",
    "            out_src, out_cls = self.D(x_fake.detach())\n",
    "            d_loss_fake = torch.mean(out_src)\n",
    "\n",
    "            # Compute loss for gradient penalty.\n",
    "            alpha = torch.rand(x_real.size(0), 1, 1, 1).to(self.device)\n",
    "            x_hat = (alpha * x_real.data + (1 - alpha) * x_fake.data).requires_grad_(True)\n",
    "            out_src, _ = self.D(x_hat)\n",
    "            d_loss_gp = self.gradient_penalty(out_src, x_hat)\n",
    "\n",
    "            # Backward and optimize.\n",
    "            d_loss = d_loss_real + d_loss_fake + self.lambda_cls * d_loss_cls + self.lambda_gp * d_loss_gp\n",
    "            self.reset_grad()\n",
    "            d_loss.backward()\n",
    "            self.d_optimizer.step()\n",
    "\n",
    "            # Logging.\n",
    "            loss = {}\n",
    "            loss['D/loss_real'] = d_loss_real.item()\n",
    "            loss['D/loss_fake'] = d_loss_fake.item()\n",
    "            loss['D/loss_cls'] = d_loss_cls.item()\n",
    "            loss['D/loss_gp'] = d_loss_gp.item()\n",
    "            \n",
    "            # =================================================================================== #\n",
    "            #                               3. Train the generator                                #\n",
    "            # =================================================================================== #\n",
    "            \n",
    "            if (i+1) % self.n_critic == 0:\n",
    "                # Original-to-target domain.\n",
    "                x_fake = self.G(x_real, c_trg)\n",
    "                out_src, out_cls = self.D(x_fake)\n",
    "                g_loss_fake = - torch.mean(out_src)\n",
    "                g_loss_cls = self.classification_loss(out_cls, label_trg, self.dataset)\n",
    "\n",
    "                # Target-to-original domain.\n",
    "                x_reconst = self.G(x_fake, c_org)\n",
    "                g_loss_rec = torch.mean(torch.abs(x_real - x_reconst))\n",
    "\n",
    "                # Backward and optimize.\n",
    "                g_loss = g_loss_fake + self.lambda_rec * g_loss_rec + self.lambda_cls * g_loss_cls\n",
    "                self.reset_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                # Logging.\n",
    "                loss['G/loss_fake'] = g_loss_fake.item()\n",
    "                loss['G/loss_rec'] = g_loss_rec.item()\n",
    "                loss['G/loss_cls'] = g_loss_cls.item()\n",
    "\n",
    "            # =================================================================================== #\n",
    "            #                                 4. Miscellaneous (기타)                              #\n",
    "            # =================================================================================== #\n",
    "\n",
    "            # Print out training information.\n",
    "            if (i+1) % self.log_step == 0:\n",
    "                et = time.time() - start_time\n",
    "                et = str(datetime.timedelta(seconds=et))[:-7]\n",
    "                log = \"Elapsed [{}], Iteration [{}/{}]\".format(et, i+1, self.num_iters)\n",
    "                for tag, value in loss.items():\n",
    "                    log += \", {}: {:.4f}\".format(tag, value)\n",
    "                print(log)\n",
    "\n",
    "                if self.use_tensorboard:\n",
    "                    for tag, value in loss.items():\n",
    "                        self.logger.scalar_summary(tag, value, i+1)\n",
    "\n",
    "            # Translate fixed images for debugging. 초기에 고정해준 영상을 사용하여 디버깅을 진행한다.\n",
    "            if (i+1) % self.sample_step == 0:\n",
    "                with torch.no_grad():\n",
    "                    x_fake_list = [x_fixed]\n",
    "                    for c_fixed in c_fixed_list:\n",
    "                        x_fake_list.append(self.G(x_fixed, c_fixed))\n",
    "                    x_concat = torch.cat(x_fake_list, dim=3)\n",
    "                    sample_path = os.path.join(self.sample_dir, '{}-images.jpg'.format(i+1))\n",
    "                    save_image(self.denorm(x_concat.data.cpu()), sample_path, nrow=1, padding=0)\n",
    "                    print('Saved real and fake images into {}...'.format(sample_path))\n",
    "\n",
    "            # Save model checkpoints. (정해진 학습횟수 단위로 모델을 저장한다.)\n",
    "            if (i+1) % self.model_save_step == 0:\n",
    "                G_path = os.path.join(self.model_save_dir, '{}-G.ckpt'.format(i+1))\n",
    "                D_path = os.path.join(self.model_save_dir, '{}-D.ckpt'.format(i+1))\n",
    "                torch.save(self.G.state_dict(), G_path)\n",
    "                torch.save(self.D.state_dict(), D_path)\n",
    "                print('Saved model checkpoints into {}...'.format(self.model_save_dir))\n",
    "\n",
    "            # Decay learning rates. learning rate를 조정해준다 (순차적으로 감소시킴)\n",
    "            if (i+1) % self.lr_update_step == 0 and (i+1) > (self.num_iters - self.num_iters_decay):\n",
    "                g_lr -= (self.g_lr / float(self.num_iters_decay))\n",
    "                d_lr -= (self.d_lr / float(self.num_iters_decay))\n",
    "                self.update_lr(g_lr, d_lr)\n",
    "                print ('Decayed learning rates, g_lr: {}, d_lr: {}.'.format(g_lr, d_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test(): 이 함수는 학습된 모델을 사용하여 실제 사용자가 원하는 사진에 대해 성공적으로 일을 수행하는지 test할때 사용되는 함수입니다. 이 함수는 한가지의 데이터집합으로 test할때 사용되고, 여러가지 데이터집합을 합쳐서 사용하게 될때는 실제 코드에 있는 test_multi() 함수를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self):\n",
    "        \"\"\"Translate images using StarGAN trained on a single dataset.\"\"\"\n",
    "        # Load the trained generator. test는 기존에 학습된 모델을 사용하여 진행하기 때문에 학습된 모델을 불러온다.\n",
    "        self.restore_model(self.test_iters)\n",
    "        \n",
    "        # Set data loader. test에 사용될 데이터집합을 로딩한다.\n",
    "        if self.dataset == 'CelebA':\n",
    "            data_loader = self.celeba_loader\n",
    "        elif self.dataset == 'RaFD':\n",
    "            data_loader = self.rafd_loader\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (x_real, c_org) in enumerate(data_loader):\n",
    "\n",
    "                # Prepare input images and target domain labels.\n",
    "                x_real = x_real.to(self.device)\n",
    "                c_trg_list = self.create_labels(c_org, self.c_dim, self.dataset, self.selected_attrs)\n",
    "\n",
    "                # Translate images. 학습된 weight들로 영상 변환을 한다.\n",
    "                x_fake_list = [x_real]\n",
    "                for c_trg in c_trg_list:\n",
    "                    x_fake_list.append(self.G(x_real, c_trg))\n",
    "\n",
    "                # Save the translated images.\n",
    "                x_concat = torch.cat(x_fake_list, dim=3)\n",
    "                result_path = os.path.join(self.result_dir, '{}-images.jpg'.format(i+1))\n",
    "                save_image(self.denorm(x_concat.data.cpu()), result_path, nrow=1, padding=0)\n",
    "                print('Saved real and fake images into {}...'.format(result_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logger.py\n",
    "----------------------------------\n",
    "logger.py는 tensorboard를 구축해주는 파일입니다. tensorboard는 학습 과정의 로그를 저장하여 웹으로 띄워서 사용자가 학습 과정과 결과에 대한 비교를 실시간으로 모니터링 하며 확인할 수 있도록 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    \"\"\"Tensorboard logger.\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Initialize summary writer.\"\"\"\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Add scalar summary.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block with instance normalization 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True, track_running_stats=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nn.sequential란  여러가지 nn.module를 한 컨테이너에 집어넣고 한번에 돌리는 방법이다.\n",
    "* nn.conv2d : (입력값,필터값,strides,padding)\n",
    "* 필터값을 각각 행렬로 정의해주고, padding인자를 통해 padding사이즈를 정한다.\n",
    "* ReLU : rectified Linear unit의 약자로 활성화 함수이다.\n",
    "* ReLU는 sigmoid function의 문제인 gradient vanishing을 해결하기위해 생겨났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 의 생성자(generator)함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자는 랜덤 벡터를 입력으로 받아 가짜 이미지를 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    #네트워크 구조\n",
    "    def __init__(self, conv_dim=64, c_dim=5, repeat_num=6):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3+c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.InstanceNorm2d(conv_dim, affine=True, track_running_stats=True))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        # Down-sampling layers.\n",
    "        curr_dim = conv_dim\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True, track_running_stats=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            curr_dim = curr_dim * 2\n",
    "\n",
    "        # Bottleneck layers.\n",
    "        for i in range(repeat_num):\n",
    "            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n",
    "\n",
    "        # Up-sampling layers.\n",
    "        for i in range(2):\n",
    "            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True, track_running_stats=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            curr_dim = curr_dim // 2\n",
    "\n",
    "        layers.append(nn.Conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.main = nn.Sequential(*layers)\n",
    "    def forward(self, x, c):\n",
    "        # Replicate spatially and concatenate domain information.\n",
    "        # Note that this type of label conditioning does not work at all if we use reflection padding in Conv2d.\n",
    "        # This is because instance normalization ignores the shifting (or bias) effect.\n",
    "        c = c.view(c.size(0), c.size(1), 1, 1)\n",
    "        c = c.repeat(1, 1, x.size(2), x.size(3))\n",
    "        x = torch.cat([x, c], dim=1)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.cat : 다른 길이의 텐서를 하나로 묶을 때 사용한다.\n",
    "* view : numpy의 reshape와 유사하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN의 구분자(Discriminator)함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 구분자는 이미지를 입력으로 받아 이미지가 진짜인지 가짜인지 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network with PatchGAN.\"\"\"\n",
    "    #네트워크 구조 \n",
    "    def __init__(self, image_size=128, conv_dim=64, c_dim=5, repeat_num=6):\n",
    "        super(Discriminator, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1))\n",
    "        layers.append(nn.LeakyReLU(0.01))\n",
    "\n",
    "        curr_dim = conv_dim\n",
    "        for i in range(1, repeat_num):\n",
    "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            curr_dim = curr_dim * 2\n",
    "\n",
    "        kernel_size = int(image_size / np.power(2, repeat_num))\n",
    "        self.main = nn.Sequential(*layers)\n",
    "        # convolution은 2차원 배열로 설정한다.\n",
    "        self.conv1 = nn.Conv2d(curr_dim, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=kernel_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.main(x)\n",
    "        out_src = self.conv1(h)\n",
    "        out_cls = self.conv2(h)\n",
    "        return out_src, out_cls.view(out_cls.size(0), out_cls.size(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LeakyReLU는 각 뉴런의 출력값이 0보다 높으면 그대로 놔두고, 0보다 낮으면 정해진 작은 숫자를 곱하는 간단한 함수다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_loader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  사람 얼굴 이미지 오픈데이터셋 (CelebA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA(data.Dataset):\n",
    "    \n",
    "    #celebA dataset 의 초기화\n",
    "    def __init__(self, image_dir, attr_path, selected_attrs, transform, mode):\n",
    "        \"\"\"Initialize and preprocess the CelebA dataset.\"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.attr_path = attr_path\n",
    "        self.selected_attrs = selected_attrs\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.train_dataset = []\n",
    "        self.test_dataset = []\n",
    "        self.attr2idx = {}\n",
    "        self.idx2attr = {}\n",
    "        self.preprocess()\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.num_images = len(self.train_dataset)\n",
    "        else:\n",
    "            self.num_images = len(self.test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### celebA  의 전처리 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(self):\n",
    "        \"\"\"Preprocess the CelebA attribute file.\"\"\"\n",
    "        lines = [line.rstrip() for line in open(self.attr_path, 'r')]\n",
    "        all_attr_names = lines[1].split()\n",
    "        for i, attr_name in enumerate(all_attr_names):\n",
    "            self.attr2idx[attr_name] = i\n",
    "            self.idx2attr[i] = attr_name\n",
    "\n",
    "        lines = lines[2:]\n",
    "        random.seed(1234)\n",
    "        random.shuffle(lines)\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            split = line.split()\n",
    "            filename = split[0]\n",
    "            values = split[1:]\n",
    "\n",
    "            label = []\n",
    "            for attr_name in self.selected_attrs:\n",
    "                idx = self.attr2idx[attr_name]\n",
    "                label.append(values[idx] == '1')\n",
    "\n",
    "            if (i+1) < 2000:\n",
    "                self.test_dataset.append([filename, label])\n",
    "            else:\n",
    "                self.train_dataset.append([filename, label])\n",
    "\n",
    "        print('Finished preprocessing the CelebA dataset...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* random.shuffle(): random모듈을 이용한 편의함수로 리턴값이 없고, 입력 시퀸스를 직접 바꾸는 in-place 연산이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지를 불러오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, index):\n",
    "        \"\"\"Return one image and its corresponding attribute label.\"\"\"\n",
    "        dataset = self.train_dataset if self.mode == 'train' else self.test_dataset\n",
    "        filename, label = dataset[index]\n",
    "        image = Image.open(os.path.join(self.image_dir, filename))\n",
    "        return self.\n",
    "    form(image), torch.FloatTensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지의 넘버 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def __len__(self):\n",
    "        \"\"\"Return the number of images.\"\"\"\n",
    "        return self.num_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data를 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loader(image_dir, attr_path, selected_attrs, crop_size=178, image_size=128, \n",
    "               batch_size=16, dataset='CelebA', mode='train', num_workers=1):\n",
    "    \"\"\"Build and return a data loader.\"\"\"\n",
    "    transform = []\n",
    "    if mode == 'train':\n",
    "        transform.append(T.RandomHorizontalFlip())\n",
    "    transform.append(T.CenterCrop(crop_size))\n",
    "    transform.append(T.Resize(image_size))\n",
    "    transform.append(T.ToTensor())\n",
    "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = T.Compose(transform)\n",
    "\n",
    "    if dataset == 'CelebA':\n",
    "        dataset = CelebA(image_dir, attr_path, selected_attrs, transform, mode)\n",
    "    elif dataset == 'RaFD':\n",
    "        dataset = ImageFolder(image_dir, transform)\n",
    "\n",
    "    data_loader = data.DataLoader(dataset=dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=(mode=='train'),\n",
    "                                  num_workers=num_workers)\n",
    "    return data_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
