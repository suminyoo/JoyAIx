{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 평점 긍정 부정 예측 AI 개발하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 파일 읽기\n",
    "--------------------------------------------\n",
    "0. 데이터 다운로드(in kaggle): https://www.kaggle.com/c/word2vec-nlp-tutorial/data\n",
    "1. 긍정과 부정 데이터가 있는 train 데이터를 읽어온다.\n",
    "2. 긍정과 부정이 없는 test데이터를 읽어온다.\n",
    "2. 판다스 라이브러리 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며 \n",
    "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
    "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
    "\"\"\"\n",
    "# QUOTE_MINIMAL (0), QUOTE_ALL (1), \n",
    "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "\n",
    "# 레이블인 sentiment 가 있는 학습 데이터\n",
    "train = pd.read_csv('labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "# 레이블이 없는 테스트 데이터\n",
    "test = pd.read_csv('testData.tsv', delimiter='\\t', quoting=3)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자료를 눈으로 확인하기\n",
    "----------------------------------------\n",
    "1. 센티멘트가 있는 train데이터를 살펴보기\n",
    "2. head()사용: 위에서 원하는 만큼 데이터를 찍어보는 함수\n",
    "3. train데이터는 sentiment가 있음을 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블인 'sentiment'가 없다. 이 데이터를 기계학습을 통해 예측한다.\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정제하기: 단어장 만들기\n",
    "------------------------------------------\n",
    "1. 문서는 다양한 단어로 이루어져있음\n",
    "2. 우리는 일종의 단어장을 만들어 볼 것이다. \n",
    "3. 우리가 중학교 때 영어 사전을 들고 다니지 않고 들고다녔던 단어장을 기억해보자!\n",
    "4. 단어장에는 중복된 단어가 없어야한다.   \n",
    "\n",
    "### 아래의 세 문장을 보자\n",
    "--------------------------------------------------\n",
    "```\n",
    "문장1: The car is expensive.    \n",
    "문장2: The truck is cheap.    \n",
    "문장3: The car is expensive and the truck is cheap.   \n",
    "```\n",
    "------------------------------------------------------\n",
    "__문장에 등장하는 단어는 7개이며 아래와 같은 알파벳 순서의 단어장을 만들어 볼 수 있다__\n",
    "```\n",
    "[and, car, cheap, expensive, is, the, truck]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어장 만들기: 텍스트를 벡터로 만들기\n",
    "------------------------------------------\n",
    "1. 단어장의 단어를 인덱스로 바꾸기\n",
    ">- and -> 0, car -> 1, ... truck -> 6으로 만들기\n",
    ">- 문장1~문장3에 등장하는 단어의 빈도수를 적어 정리하기\n",
    ">- 문장1~문장3의 특성을 나타내는 표로 배열 즉, 벡터로 구성함\n",
    "2. scikit-learn의 CounterVectorizer: 위에서 설명한 텍스트 문장을 벡터로 구성하는 것을 해주는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 1 0]\n",
      " [0 0 1 0 1 1 1]\n",
      " [1 1 1 1 2 2 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "txt1= 'the car is expensive'\n",
    "txt2= 'the truck is cheap'\n",
    "txt3= 'the car is expensive and the truck is cheap'\n",
    "\n",
    "count= CountVectorizer()\n",
    "docs = np.array([txt1, txt2, txt3])\n",
    "bag = count.fit_transform(docs)\n",
    "\n",
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어장 만들기: tf-idf기법 사용하여 빈도수 체크하기\n",
    "-----------------------------------------\n",
    "1. tf-idf기법이란?\n",
    ">- 문장에서 등장하는 단어가 훈련에 쓸만한 정보를 가지고 있는지 빈도수를 통해 판단하기 위해서 사용함.\n",
    ">- 영어 단어 'is'와 같은 be동사에 적용됨: 등장하는 빈도수는 높지만 큰 의미를 둘만한 단어가 아님\n",
    ">- 공식: tf-idf(t,d) tf(t,d) * (idf(t,d)+1)\n",
    ">- sklearn은 tf.idf(t,d)계산을 위해 TfidTrnasformer()클래스를 제공함\n",
    "2. sklern의 TfidTransformer클래스를 라이브러리에 추가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.56 0.   0.56 0.43 0.43 0.  ]\n",
      " [0.   0.   0.56 0.   0.43 0.43 0.56]\n",
      " [0.4  0.31 0.31 0.31 0.48 0.48 0.31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "np.set_printoptions(precision=2)# tf-idf(t,d)값의 L2정규화 값을 계산\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__결과를 보면 0과 1의 값이 tf-idf를 적용한 뒤 소수점으로 다른 값이 나오는 것을 확인할 수 있다. 이렇게 바뀐 이유는 tf-idf가 문장에서의 특정 단어의 빈도수로 바꾸어주었기 때문이다__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장을 컴퓨터가 읽기 편하게 만들기\n",
    "------------------------------------------------------\n",
    "#### step1: html 태그 제거\n",
    "#### step2: 영문자가 아닌 문자는 공백으로 변환\n",
    "#### step3: 소문자 변환\n",
    "#### step4: 동사를 동사원형으로 만들기\n",
    "#### step5: 단어들을 합쳐서 문장으로 다시 재결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html 태그가 섞여있기 때문에 이를 정제해줄 필요가 있음\n",
    "train['review'][0][:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 시작\n",
      "전처리 완료: 소요시간 [3]초\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "def preprocessor(text):\n",
    "    #특수기호, HTML 테그 등 제거\n",
    "    text = re.sub('<[^>]*>','',text)\n",
    "    text= re.sub('[^a-zA-Z]',' ',text)\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "train = pd.read_csv('labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "\n",
    "stime = time()\n",
    "print('전처리 시작')\n",
    "train['review'] = train['review'].apply(preprocessor)\n",
    "print('전처리 완료: 소요시간 [%d]초' %(time()-stime))\n",
    "\n",
    "train.to_csv('refined_labeledTrainData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds   by timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager  nicholas bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1   with all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1     the classic war of the worlds   by timothy ...\n",
       "2  \"7759_3\"          0   the film starts with a manager  nicholas bell...\n",
       "3  \"3630_4\"          0   it must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1   superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('refined_labeledTrainData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__review에 문장부호가 사라졌고 모두 소문자로 바뀐 것을 볼 수 있다__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장을 단어로 쪼개기\n",
    "-------------------------------------------------\n",
    "1. nltk를 설치함\n",
    ">- 문장에서 단어를 분리하는 파이썬 확장 라이브러리\n",
    ">- 자연어 처리와 관련된 다양한 api제공\n",
    ">- 다음 사이트를 설명을 참고하여 설치할 것http://ling.snu.ac.kr/class/cl_under1801/InstallationGuideforWindowUsers.pdf\n",
    "2. tokenizer(), tokernizer_porter()함수로 각각 공백으로 단어를 분리하여 리스트로 리턴한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#공백으로 단어 분리\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "#Porter Stemming 알고리즘을 이용해 단어분리\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 데이터로 학습 모델 만들기\n",
    "---------------------------------------------\n",
    "1. 25000개의 리뷰 데이터에 모두 적용하기\n",
    "\n",
    "2. scikit-learn에서 CountVectorizer()과 TfidTransformer()의 기능을 합쳐놓은 TfidVectorizer()클래스를 사용하기\n",
    ">- 영화 리뷰 문장을 특정 벡터로 구성하고\n",
    ">- 로지스틱 회귀 알고리즘으로 머신러닝 수행하기\n",
    "\n",
    "3. 완성된 모델은 pklObject이름의 파일로 저장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머신러닝 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머신러닝 종료\n",
      "테스트 종료: 소요시간 [12]초\n",
      "정확도: 0.925\n",
      "머신러닝 데이터 저장 완료\n"
     ]
    }
   ],
   "source": [
    "#입력받은 리스트에 정의된 함수를 순차적으로 적용해주는 라이브러리\n",
    "from sklearn.pipeline import Pipeline \n",
    "#로지스틱 회귀 알고리즘 라이브러리\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "#CountVectorizer()과 TfidTrnasformer()을 sklearn의 클래스 \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#특정 벡터로 구성하는 라이브러리\n",
    "from sklearn.metrics import accuracy_score\n",
    "#만든 모델을 파일로 저장해주는 라이브러리\n",
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "#정제했던 데이터 불러오기\n",
    "df = pd.read_csv('refined_labeledTrainData.csv')\n",
    "#전처리된 영화 리뷰 train데이터 15000개를 이용해 머신러닝을 수행함\n",
    "\n",
    "# 머신러닝의 결과는 10000개의 test데이터로 검증해봄\n",
    "X_train = df.loc[:15000,'review'].values\n",
    "Y_train = df.loc[:15000,'sentiment'].values\n",
    "X_test = df.loc[10000:,'review'].values\n",
    "Y_test = df.loc[10000:, 'sentiment'].values\n",
    "\n",
    "#tokenizer()로 단어를 공백으로 분리하고 TfidVectorizer()에 넣어줌\n",
    "tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "#pipeline의 parameter은 (함수별명, 함수)같은 튜플로 만들어야 함\n",
    "#따라서 함수 별명이 vect인 lr_tfidf인 튜플과\n",
    "#clf가 별명인 tfidf튜플을 넣어준다. \n",
    "Ir_tfidf = Pipeline([('vect',tfidf),('clf',LogisticRegression(C = 10.0, penalty = 'l2', random_state = 0))])\n",
    "\n",
    "#시간 계산 함수\n",
    "stime = time()\n",
    "print('머신러닝 시작')\n",
    "#X_train과 Y_train을 이용하여 머신러닝을 수행함.\n",
    "Ir_tfidf.fit(X_train, Y_train)\n",
    "print('머신러닝 종료')\n",
    "\n",
    "Y_pred = Ir_tfidf.predict(X_test)\n",
    "print('테스트 종료: 소요시간 [%d]초' %(time()-stime))\n",
    "print('정확도: %.3f' %accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#머신러닝 결과를 pickle 모듈의 dump()를 이용하여 파일로 저장함\n",
    "curDir = os.getcwd()\n",
    "dest = os.path.join(curDir,'data','pklObject')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(Ir_tfidf,open(os.path.join(dest,'classifier.pkl'),'wb'),protocol=4)\n",
    "print('머신러닝 데이터 저장 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자로부터 입력받은 값을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 0.925\n",
      "영문으로 리뷰를 작성하세요: i've never seen a great movie.\n",
      "예측: 긍정적 의견\n",
      "확률: 99.960%\n",
      "영문으로 리뷰를 작성하세요: Never Look Away fills its protracted running time with the absorbing story of an incredible life -- and its impact on the singular artist who lived it.\n",
      "예측: 긍정적 의견\n",
      "확률: 95.426%\n",
      "영문으로 리뷰를 작성하세요: Everybody Knows is somewhat less than the sum of its parts despite the efforts of an outstanding cast - and a disappointing step back for writer-director Asghar Farhadi.\n",
      "예측: 부정적 의견\n",
      "확률: 83.059%\n",
      "영문으로 리뷰를 작성하세요: i hated this movie.\n",
      "예측: 부정적 의견\n",
      "확률: 98.556%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('refined_labeledTrainData.csv')\n",
    "\n",
    "X_train = df.loc[:15000,'review'].values\n",
    "Y_train = df.loc[:15000,'sentiment'].values\n",
    "X_test = df.loc[10000:,'review'].values\n",
    "Y_test = df.loc[10000:, 'sentiment'].values\n",
    "\n",
    "curDir = os.getcwd()\n",
    "clf = pickle.load(open(os.path.join(curDir,'data','pklObject','classifier.pkl'),'rb'))\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "print('테스트 정확도: %.3f' %accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "label = {0: '부정적 의견', 1:'긍정적 의견'}\n",
    "\n",
    "while True:\n",
    "    txt = input(\"영문으로 리뷰를 작성하세요: \")\n",
    "    if txt == '':\n",
    "        break\n",
    "        \n",
    "    example = [txt]\n",
    "    print('예측: %s\\n확률: %.3f%%' %(label[clf.predict(example)[0]], np.max(clf.predict_proba(example))*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
