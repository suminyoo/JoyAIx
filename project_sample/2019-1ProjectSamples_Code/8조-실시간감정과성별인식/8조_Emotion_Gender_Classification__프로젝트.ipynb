{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion/Gender Classification 프로젝트\n",
    "### 실시간으로 사람들의 감정 상태와 성별을 탐지하는 AI 프로젝트\n",
    "### 모두를 위한 인공지능 Final project - 8조 최은송(21500747) / 김나연(21900075)\n",
    "--------------------------------------------\n",
    "\n",
    "#### 프로젝트 소개\n",
    "\n",
    "CNN 모델과 openCV를 통해 실시간으로 사람의 얼굴을 탐지하고 감정과 성별을 구별할 수 있다.\n",
    "Real-time face detection and emotion/gender classification using fer2013/IMDB datasets with a keras CNN model and openCV.\n",
    "\n",
    "링크 > https://github.com/oarriaga/face_classification\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "#### 프로젝트 목표\n",
    "\n",
    "1. 실시간으로 사람들의 얼굴을 탐지하고 감정, 성별을 구분할 수 있다.\n",
    "2. openCV와 keras CNN을 사용한 학습 모델의 구조를 이해할 수 있다.\n",
    "3. 성별, 감정 데이터셋을 다운받아서 직접 인공지능 모델을 학습시킬 수 있다.\n",
    "\n",
    "----------------------------------------------\n",
    "\n",
    "#### 프로젝트 개요\n",
    "\n",
    "1. git에서 face_classification 프로젝트 다운로드\n",
    "2. openCV 설치\n",
    "3. IMDB gender classification 데이터와 fer2013 emotion classification 데이터를 다운받아서 예측 모델 학습\n",
    "4. 이미지 모델에 사진을 입력해서 성별, 감정 탐지하기\n",
    "5. 비디오 모델을 이용해 실시간 웹캠으로 감정 탐지하기\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "#### 맥 유저를 위한 openCV 설치 명령어\n",
    "\n",
    "~~~\n",
    "sudo python3.7 -m pip install --upgrade pip setuptools wheel\n",
    "sudo pip3 install opencv-python\n",
    "~~~\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script \n",
    "\n",
    "안녕하세요 실시간으로 사람들의 감정 상태와 성별을 탐지하는 AI 프로젝트를 진행한 8조 최은송, 김나연 입니다.\n",
    "다음은 저희 emotion/gender classification 프로젝트 목표입니다. \n",
    "\n",
    "다음은 저희 프로젝트의 개요입니다. 이 동영상을 통해 우리는 5가지 항목을 함께 하게 될 것입니다. 우선 git에서 face classification 프로젝트를 다운받습니다. 그 다음 영상처리를 위한 openCV 라이브러리를 함께 설치해 보겠습니다. 모델을 학습하기 위해 IMDB gender classification 데이터와 fer2013 emotion classification 데이터를 다운받아서 예측 모델을 학습시켜 줍니다. 그 다음으로 이미지 모델에 사진을 입력해서 성별, 감정을 탐지할 것입니다. 마지막으로 비디오 모델을 이용해서 실시간 웹캠으로 우리 얼굴과 감정, 성별을 탐지할 것입니다.\n",
    "\n",
    "다음은 저희 프로젝트의 시스템 개요도입니다. 먼저 이미지를 openCV를 이용해서 입력받습니다 . 그 다음 미리 학습하고 저장해 놓은 모델에 이미지를 넣으면 모델이 사람의 얼굴을 탐지해서 얼굴 주위에 박스를 그리고 결과로 나온 성별과 감정을 박스 좌측 상단에 텍스트로 적어서 결과 사진을 저장합니다.  ",
    "\n",
    "이것은 학습 모델의 내부 개요도 입니다. 개요도를 보면서 간략하게 모델이 어떻게 작동하는지 설명해 드리겠습니다. 저희는 이미지를 인풋값으로 주기 때문에 영상 인식에서 특징을 뽑아낼때 주로 사용하는 conv2d 레이어를 사용했습니다. Conv2d 옆에 보면 batch normalization이라는 레이어가 있는데 이것은 활성화 함수의 활성화값을 정규화시켜 주어서 전체 학습속도를 빠르게 만드는 역할을 합니다. 중간에 있는 레이어들은 학습을 위해 쌓아준 conv2d 관련 레이어들이구요, 위의 global avg, pooling 2d, softmax 레이어는 우리가 원하는 결과 레이블을 분류하기 위해 사용했습니다.\n",
    "\n",
    "우리 감정 예측 모델은 분노, 역겨움, 공포, 행복, 슬픔, 놀람, 중립 총 7가지의 감정을 탐지할 수  있지만 실제로 실험해본 결과 저장된 학습 모델에서는 분노, 행복, 슬픔, 놀람, 중립 5가지만 탐지할 수 있었습니다. 오른쪽의 사진은 사진을 이미지 감정 예측 모델에 넣었을 때 실행된 결과입니다.\n",
    "\n",
    "위 사진은 이미지 모델에 사진을 넣었을 때 사람의 성별과 감정을 탐지하고 결과로 저장한 사진입니다. 앞의 남자 얼굴에 빨간색 박스가 쳐져있고 neutral, men이라고 적혀있는것을 볼 수 있고 뒤의 여자 얼굴엔 파란색 박스에 happy, woman 글씨가 적혀있는 것을 볼 수 있습니다.\n",
    "\n",
    "비디오 모델을 이용해 웹캠으로 실시간 얼굴과 감정을 탐지하는 영상입니다. 보시다시피 표정이 변할때마다 실시간으로 감정 텍스트와 박스 색깔이 변하는걸 볼 수 있습니다.\n",
    "\n",
    "그러면 저희는 이 순서대로 프로젝트를 진행하겠습니다. 먼저 git에서 프로젝트 설치하는 것부터 해보겠습니다.\n",
    "프로젝트 git에 가서 clone or download 버튼을 누르고 download Zip을 눌러서 프로젝트를 다운받습니다. 시간이 좀 걸리기 때문에 저는 미리 프로젝트를 다운받았습니다.  그 후에 다운받은 프로젝트를 자신이 작업할 폴더로 이동시켜주고 압축을 풀어줍니다.  \n",
    "\n",
    "그 다음 프로젝트를 실행하기 위해 openCV를 설치해 볼 것입니다. 저는 일단 맥을 사용하기 때문에 맥에서 opencv를 설치하는 것을 진행할 것입니다. 터미널을 켜서 python3.7을 위해 pip을 업그레이드 해주세요. 그 후에 python용 opencv를 pip으로 설치하겠습니다. 설치가 끝나면 jupyter notebook을 켜서 아무 파일이나 python3로 만들어 주시고 import cv2라고 쳐서 실행해봅니다. 에러없이 잘 실행이 되었다면 opencv가 잘 설치되신 겁니다.\n",
    "\n",
    "그 다음 성별 데이터와 emotion 데이터를 다운받아서 예측 모델에 학습해보는 것을 해보겠습니다. 성별 데이터는 너무 크고 오래걸리기 때문에 저희는 감정 데이터만 학습해보겠습니다 다시 git에 가셔서 here을 클릭해줍니다. Download all을 눌러서 데이터를 다운받습니다. 시간이 좀 걸려서 저는 미리 다운받았습니다. 그 다음 데이터를 프로젝트 폴더 안에 넣어주세요. 여기 datasets 빈 폴더가 보이실 겁니다. 데이터 압축을 풀어주고 fer2013 폴더만  datasets 폴더에 넣어주세요. 그러면 모델을 학습하기 위한 데이터 준비가 끝났습니다. 저희는 주피터 노트북에서 프로젝트를 진행할 것이기 때문에 주피터 노트북을 키고 face classification 프로젝트 폴더로 들어갑니다. Src 폴더로 들어가시면 train_gender_classification 파일이 보이는데 이 파일을 클릭하세요. 이제 이 파일을 모두 선택해서 복사하고 다시 새로운 python파일을 생성해서 붙여넣어 줍니다. 파일 이름은 train_emotion_jupyter로 하겠습니다. 이 파일을 저장하고 실행해 보겠습니다. 그러면 학습이 시작된것을 볼 수 있습니다. 이 표들은 학습 모델을 구성하는 레이어와 뉴런 숫자들이고 밑에 보시면 training dataset: fer2013이라는 글자가 적힌 것을 볼 수 있습니다. 아까 우리가 다운받았던 fer2013 데이터를 학습하는 것입니다. 지금 10000개의 epoch 중에 첫번째 epoch가 학습되고 있는 것이 보이는데 손실율이 1.9~이고 정확도가 0.2~밖에 안되네요. 나중에 학습이 다 끝나면 정확도가 96%까지 올라가는데요, 아직 아직 epoch1이라서 한참 낮습니다. 학습을 전부 하려면 한참 걸릴 것 같아서 일단 학습은 여기서 중단하겠습니다.\n",
    "\n",
    "그 다음 학습까지 마쳤으니 이미지 모델에 사진을 입력해서 성별, 감정 분류하는 프로젝트를 해보겠습니다. 다시 jupyer notebook에 들어가서 image_emotion_gender_demo 파일을 클릭해서 들어갑니다. 아까처럼 전체 선택하고 복사하고 나와서 새로운 파일을 만들어서 붙여줍니다. 파일의 이름은 image_model_jupyter라고 해주겠습니다. 저희는 이 코드를 살짝 수정할 건데요 face_classification 파일의 images 파일 안에 사진을 추가해주면 그 사진을 모델이 자동으로 인식해서 결과 사진을 띄우고 저장하게 할 것입니다. 우선 사람 얼굴이 잘 나온 사진을 Images 폴더에 추가해 줍니다. 사진 이름은 people입니다. 그다음 다시 코드로 돌아가서 모델에 자동으로 people 이미지를 입력하게 하는 코드를 추가해 줄 것입니다. 코드 위에 import os를 적어줍니다. 이것은 사진의 path를 찾기 위해 사용되는 library입니다. 이 sys.argv[1]은 터미널에서 사진을 바로 입력해줄 때 사용하는 명령어인데요 우린 이걸 지우고 아까 people.jpg 사진을 저장했던 경로를 써 줍니다. 아까 images 폴더에 people.jpg로 저장해 주었죠. 그 다음 우리는 학습 결과로 나온 사진을 result라는 폴더에 저장해 주길 원합니다. 저장할 폴더의 이름을 result로 정해주고 폴더가 없으면 만들라는 명령어를 추가해 줍니다. 그 다음에 result 폴더에 result.png라는 이름으로 결과 사진인 bgr_image를 저장해 주는 코드를 추가해 줍니다. 그다음 실행을 해보겠습니다. 아 에러가 떴네요.  이것은 color_mode가 없어서 뜨는 에러인데요 src/util/inference.py 파일로 가서 color_mode를 추가해 주겠습니다. 자 다시 코드로 돌아와서 실행해 주겠습니다. 그러면 결과로 감정과 성별이 분류되어서 박스가 쳐진 사진이 뜨는 것을 볼 수 있습니다. 폴더를 확인하면 아까 없던 result 폴더가 생기고 result 이름으로 결과 사진이 저장되었습니다.\n",
    "\n",
    "\n",
    "자 이제 마지막으로 비디오 모델을 이용해 실시간 웹캠으로 감정 탐지하기를 해보겠습니다. 이전과 마찬가지로 주피터 노트북에 가서 video_emotion_gender_demo.py 파일을 클릭해서 들어갑니다. 전체 선택해서 복사하고 나와서 새로운 파일을 만들어서 그곳에 붙여넣기를 해줍니다. 이 파일의 이름은 video_model_jupyter라고 하겠습니다. 이제 바로 코드를 실행해 보겠습니다. 그러면 파일이 실행되면서 웹캠이 켜지는 것을 볼 수 있습니다. 웃는것도 잘 인식하구요놀라는것도 잘 인식하네요. 그럼 q 버튼을 눌러서 웹캠을 꺼주겠습니다. \n",
    "\n",
    "네 이상으로 실시간으로 사람들의 감정 상태와 성별을 탐지하는 AI 프로젝트를 마치겠습니다. 다들 수고하셨습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
